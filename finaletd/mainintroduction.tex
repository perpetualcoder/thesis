\begin{comment}
This chapter provides the background information regarding the problem discussed in the thesis. Section
~\ref{intro:gc} describes the fundamental idea behind necessity of garbage collection. Advanced readers can skip the section ~\ref{intro:gc}. Section ~\ref{intro:motv} discusses the advantages of the garbage collection and problem statement of the thesis. Section ~\ref{intro:contr} describes all the contributions of this thesis to solve the problem mentioned in section ~\ref{intro:motv}. Section ~\ref{intro:do} helps the readers to understand how the thesis is organized.
\end{comment}
\section{Garbage Collection}
\label{intro:gc}

A processor, an algorithm (software), and memory are the trio of computation. Memory is organized by programming languages and developers to control the life of data. In this thesis, we abstract all data allocated in memory as objects. In general, we define an object as any block of memory that saves information and may contain address of other objects. Most programming languages support dynamic memory allocation. Programming languages divide available memory into three types: 
\begin {comment}
All programming languages are designed to perform complex computations. Computation contains three main ingredients : Processing unit, algorithm, and memory. Processing unit i.e., the processor is the unit which performs arithmetic, and logical operations required. Algorithm dictates the sequence of operation to performed on the data to get the desired output. Algorithm implemented in a programming language is usually referred as program and collection of programs are called software. Memory saves the input, intermediate results and final output of the computation. 
In this thesis, we are more concerned with object-oriented programming languages and object represents user-defined dynamically allocated data. Developers write algorithms in a specific programming language. Programming language organizes the memory consumed by the algorithm. Modern programming languages use three different memories to organize it.
\end{comment} 
 stack, static and heap memory. Static memory contains all the global variables used by the program. Stack memory is used to manage static (fixed size) allocation of objects whose scope is well defined. Heap memory is used to manage dynamically allocated objects whose scope cannot be determined at compile time. 

The amount of static memory used is computed at the compilation phase and objects allocated in static memory is never deleted. Stack memory is used to manage function calls and the allocation of objects in a function's scope. So the size of the stack memory required for the execution cannot be computed at compilation time. Stack memory is filled from the lower address space of memory and heap memory is filled from the higher address space of memory. When two kinds of memory meet, the program usually crashes. 

Stack memory is used to store all objects that are actively in use or will be used in the near future. Heap memory is used to store all objects whose scope is unknown to the program. Memory management is the term used to describe management of the heap. When developers explicitly delete objects that are no longer in use, it is called manual memory management. 

There are three issues that happen when the heap is manually managed. They are dangling pointers, double-free bugs, premature deletion, and memory leaks. All of the three issues are deadly and harmful. Some of them produce wrong output, deletes memory that is in use, and also inefficiently organizes the heap memory.  Apart from all the above-mentioned problems, it is extremely difficult to manually manage memory for a certain class of programs called concurrent programs. Automatic memory
management avoids all the above-mentioned problems.
This thesis focuses on designing efficient algorithms for automatic memory management. The process of automatically managing memory is termed as \textbf{Garbage Collection (GC)}.
\begin{comment}
Heap memory helps a developer to extend the life of dynamically allocated objects. Some object allocated in the heap might get a very long life as long as the life of the program running. So these objects have an infinite life if the programmer did not delete them after their last use. The unwanted objects in the heap occupy the heap memory and might make an application run out of memory and exit. In order to avoid pseudo full heap memory errors, programmers determine the life of the dynamically allocated objects and delete them. The dynamically allocated objects can be accessed only by pointers in the static and stack memory. These pointers are also called as \textbf{roots}.
\end{comment}
\subsection{How GC's work}
The term garbage refers to the objects allocated in the heap that are not used anymore. All objects allocated in memory can be reference by their address. An object $x$ is said to hold a reference to object $y$ when $x$ contains the address of $y$. 
An object is said to be in use if it is reachable through a chain of references starting from stack or static memory.
%To use any object allocated in heap memory, an object in the stack %or static memory must be able to read content in the object through %the reference saved in the object itself or through a chain of %references in multiple object chain.
The objects in stack and static memory that are considered for defining the whether an object in use are referred as \textbf{roots}.
When an object is declared as unused, it is called garbage object.
 Dead is an alternative adjective used to describe a garbage object. Garbage collection is the process of collecting all dead objects in the heap memory. 

There are two major techniques to identify garbage objects.They are tracing and reference counting. Tracing involves marking all the object in the heap that is in use by going through all the chain of references from roots. Once the marking is done, all unmarked objects in the heap are considered as garbage and deleted by the garbage collection program. Reference counting approach attaches a counter to each object that counts the number of objects that holds a reference to it. When the counter reaches zero, the object identifies that it is garbage and deletes itself. All available garbage collection algorithms are some combination of these two techniques.

\section{Motivation and Objectives}
\label{intro:motv}
Developers are using managed languages and runtime systems for several benefits including no dangling pointers, no double free bugs, no memory leaks, high productivity, and less code to write ~\cite{Butters}.  
\begin{comment}
The main advantage of the garbage collections are 
\begin{enumerate}
\item Dangling Pointers
\item Double free bugs
\item Memory Leaks
\end{enumerate}
\end{comment}
\paragraph{Dangling Pointers:}
Dangling pointers are those references in
the object where developer deleted the object a reference points, but still hold the address of the object in another object. So these references are very dangerous in nature as one does not know what the reference points to. If the reference points to some other object, then computation might yield undesired output or crash because of mismatch in type information of the object. The cost of these errors is very high. If a developer did not realize the dangling pointers are available, then the program crash.
\paragraph{Double free bugs:}
Double free bugs is an issue that happens when an object allocated in the heap is deleted at some point in time and programmer deletes the object again at the same address. It is very risky and can lead to dangling pointers in some cases. If no new objects are created at the same address, then the delete will crash the program. In other extreme cases where some object is allocated at the same address, it deletes the object and creates dangling pointers for all the object that holds a reference to deleted object. 
\paragraph{memory leaks:}
The most important of all is that the object is allocated in the heap and it is not used. The unused object is not deleted and it consumes memory which could be reused for other objects. This inefficient organization of heap can affect the runtime of an application heavily. This affects the memory allocator as there will be less memory available to allocate and program crashes when there is no memory available to allocate memory for more objects.

These advantages are very crucial for successful execution of any application. This thesis focuses on concurrent programs and automatic memory management requirement in concurrent programs. 

Concurrent programs are termed used to describe multiple programs running simultaneously to perform some computation. There are two different environments where concurrent programs are used : Shared memory and distributed memory systems. Shared memory systems contain multiple processors / multi-core processors sharing a common memory to execute the threads / processes. Thread communicate using shared memory and may use atomic instructions or traditional lock to execute some critical sections of the program. 
In shared memory environment, concurrent programmers use smart pointers to manually manage memory. Smart pointers are manual reference counting technique implemented by application programming interface. Distributed memory systems contain multiple processors with dedicated memory and processors are separated by some physical distance and connected via the network. Distributed memory system multiple processes running on each processor and processes communicate by sending messages across the network to perform the computation. Both of the environment contain programs that run concurrently and requires some form of communication to perform desired computation. Both of the environment uses automatic memory management features to help developers build applications. 

When concurrent programs are written by developers, the manual memory management is extremely difficult and error-prone. When multiple threads access a common object, the dangling pointers are common scenario due to the incomplete information about ownership. Double free bugs can occur just as frequent as the dangling pointers. Smart pointers are defacto standards to avoid memory management issues in the concurrent programs. These smart pointers do not guarantee complete garbage collection unless until carefully used. The use of cyclic objects in the heap memory requires extreme care in a manually managed concurrent program. It is carefully avoided by all programmers usually to make the program memory leak free. The above reasons explain how difficult the automatic memory management in the concurrent programming environment is and the necessity for high-quality automatic memory management in concurrent programming environments. 

Beyond solving the garbage collection in concurrent programming environment, the main objectives of this thesis are to design garbage collectors for shared and distributed memory system that satisfy the following properties :
\begin{enumerate}
	\item Concurrent garbage collectors (Less pause time)
	\item Multi-collector garbage collection
	\item No global synchronization (High Throughput)
	\item Locality based garbage collection
	\item Scalable
	\item Promptness
	\item Safety
	\item Completeness
\end{enumerate}

There are no garbage collection algorithms available for shared and distributed memory systems that satisfy all the above-mentioned properties.  This thesis focuses on designing novel garbage collector with significant improvement. Apart from garbage collection, the ideas presented in the thesis will be of use to solve other theoretical problems in distributed computing like dynamic reachability, breaking cycle, detecting cycles in graph, data aggregation in the sensor network, broken network detection in sensor networks.


\paragraph{Concurrent:}
Concurrent garbage collectors work simultaneously with the application. The application will not experience any pause during execution to scan the memory. They
have negligible to zero pause time. There are a handful of collectors that satisfy this property. 
\paragraph{Multi-collector Garbage :}
Multi-collector garbage collectors are multiple independent garbage collector thread / process that works independently on the heap to identify garbage. These collectors utilize multiple processors when there is a lot of compute resources being underutilized. In shared memory systems, when multiple processors are underutilized, this property helps to utilize processor cycles better. Apart from the processor utilization, the throughput of garbage collectors can be increased by multi-collector garbage collectors. These multi-collector garbage collector threads / processes communicate among themselves through memory in shared memory systems and through messages in distributed memory systems.
\paragraph{Global Synchronization:}
Multi-collector garbage collectors are common among distributed memory systems. 
When multi-collector garbage collectors are used, conventional solutions require global barrier among all the collectors to communicate and share the information to identify garbage objects and delete them. With no global synchronization, the throughput of garbage collectors will be high and garbage collector algorithm scales well with this property.
\paragraph{Locality based garbage collection:}
Detecting garbage is a global predicate. Traditionally, popular methods of garbage collection algorithm involve computing garbage as the global predicate. This requires scanning entire heap for precise evaluation of the predicate. If garbage object can be detected locally based on the small set of object, then the garbage detection process can save a lot of time spent on tracing all objects in the heap.
\paragraph{Scalable:}
In a shared memory system, the conventional single-threaded garbage collector does not scale well with an increase in the size of memory and number of processor. A locality based concurrent multi-collector garbage collector is hope for achieving scalability in shared memory systems.
With increase in the size of distributed global heap memory and  a number of nodes in distributed memory systems, conventional garbage collection techniques will not scale with global synchronization and scan the entire heap(s). A distributed garbage collection algorithm must be scalable to meet the future demands. Locality based garbage collection with no globally synchronized multi-collector mechanism is the best bet to scale. Related works in each of the collector chapters describe the scalability scenario in both environments. To my knowledge, there are no completely scalable garbage collectors in both environments.
\paragraph{Promptness:}
With global garbage collection, the cost of scanning entire heap often is very expensive. To reduce the high price for global scanning of the heap, garbage collection is initiated when the threshold is met. Promptness property helps to keep heap memory free of floating garbage instantly. This property helps to avoid global scanning and also easy availability of free memory for allocation.
\paragraph{Safety:}
Safety property is the most crucial part of the garbage collection which is directly related to advantages of using garbage collection. This avoids any dangling pointers and double free bugs. The property guarantees that every garbage collector will delete only garbage object. While most garbage collector in literature satisfies this property, there are some that cannot satisfy this property. This thesis requires garbage collector to be safety in the multi-collector environment which is challenging given that there is no global synchronization. In distributed memory system, the property is very difficult to satisfy as the garbage collector cannot get the global snapshot of a heap at any point in time. Locality based algorithm works only by using information obtained from neighbors. Evaluating a global predicate using local information is challenging by all means. This thesis guarantees the safety of collectors designed for both environments.
\paragraph{Completeness:}
Completeness helps garbage collector to claim that it collects all garbage objects in the heap, thereby no memory leaks in the heap . Reference counting garbage collector is well known for incomplete garbage collection due to their inability to collect cyclic garbage. This property is challenging as the locality based collectors usually use reference counting. Garbage collector with localized decision-making guarantee completeness is necessary to make the collector highly adaptable to enhance the performance of the applications. Collectors designed for both environments uses reference counting based technique to solve the problem and guarantees the garbage collectors are complete.
\section{Contributions}
\label{intro:contr}
The thesis main contributions are listed below :
\begin{enumerate}
	\item First known garbage collectors that satisfy all the above-mentioned properties in both shared memory and distributed memory system is introduced in this thesis.
	\item Novel reference counting based technique is used to collect any garbage including cyclic garbage.    
	\item First known concurrent multi-collector reference counting based garbage collector is introduced in this thesis.
	\item Well known issues in Brownbridge garbage collectors are fixed and complete and safe garbage collector is designed after three successive failures.
	\item Theoretically, our shared memory garbage collector detects garbage traverses affected the graph of objects 7 traversals less than the state of the art concurrent reference counted garbage collector.
	\item This thesis presents first known locality based concurrent multi-collector scalable garbage collector with no global synchronization in the distributed memory system. The garbage collector contains complete proof of the system.
	\item Distributed garbage collector introduces a novel weight based approach to convert the graph into directed acyclic graph and thereby detecting cycles faster.
	\item Garbage collector that finishes in linear time in a number of edges in the affected subgraph, a part of an original subgraph is better than tracing entire heap in the distributed memory systems.
\end{enumerate}
\section{Dissertation Organization}
\label{intro:do}
The preliminaries ideas required to understand the thesis is presented in the chapter ~\ref{prelim}. The chapter ~\ref{prelim} introduces the abstract version of garbage collection problem, a brief literature review of garbage collectors in general, and in detail, it explains Brownbridge garbage collector and the reasons for its failure. The understanding of Brownbridge is essential for this thesis as our algorithms extend the approach. The chapter ~\ref{shared} contains the brief introduction of shared memory garbage collectors, related works of the particular class of garbage collectors used in shared memory systems. Shared memory single collector and multi-collector algorithms are described in the chapter ~\ref{shared}. Apart from describing the algorithm, the chapter also contains the proofs of safety and completeness with simulated experimental results. The chapter also proves the linearity in a number of operations to detect garbage. The chapter ~\ref{distributed} explains the overview of distributed garbage collection, existing algorithms and their issues. Single collector and multi-collector distributed garbage collector algorithms are explained in abstract and introduce a novel technique to prove termination of garbage collection, safety, completeness and time complexity using isolation property. The chapter also includes the pseudocode of the algorithm. The distributed garbage collector is a theoretical leap in solving the problem in with scalability and other guarantees mentioned. The chapter ~\ref{conc} captures the overall contributions of the thesis in broad view with possible future works.